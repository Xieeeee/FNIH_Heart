{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "from multiprocessing import Pool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "base_dir = \"/nfs/lab/projects/mega_heart/CAREHF/multiome/\"\n",
    "assets_dir = os.path.join(base_dir, \"Assets\")\n",
    "\n",
    "cell_ranger_dir = os.path.join(base_dir, \"cellranger.symlinks\")\n",
    "\n",
    "step1_dir = os.path.join(base_dir, \"Analysys/1_preprocessing/\")\n",
    "step2_dir = os.path.join(base_dir, \"Analysys/2_PeaksReformat/\")\n",
    "step3_dir = os.path.join(base_dir, \"Analysys/3_SoupX/\")\n",
    "step4_dir = os.path.join(base_dir, \"Analysys/4_Doublet_cleanup/amulet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KA_49_1_2_KA_45_1_2\n",
      "/nfs/lab/projects/CARE_HF/DATA/multiome/LA/KA_49_1_2_KA_45_1_2/outs/\n"
     ]
    }
   ],
   "source": [
    "# Load sample info\n",
    "sample_info = pd.read_csv(os.path.join(assets_dir, \"sample.info\"), sep=\"\\t\", header=0)\n",
    "\n",
    "# Build variables\n",
    "sample_ls = sample_info[\"ID\"].tolist()\n",
    "cellranger_outs_ls = [\n",
    "    f\"{row['CellRanger']}{row['Chamber']}/{row['ID']}/outs/\"\n",
    "    for _, row in sample_info.iterrows()\n",
    "]\n",
    "\n",
    "# Check the paths are correct\n",
    "print(sample_ls[0])\n",
    "print(cellranger_outs_ls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Single cell indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(i):\n",
    "    gc.collect()\n",
    "    # Set sample variable\n",
    "    sample = sample_ls[i]\n",
    "    print(\"Workin on: \" + sample)\n",
    "    sample_dir = cellranger_outs_ls[i]\n",
    "    # load QC\n",
    "    metrics = pd.read_csv(sample_dir + \"per_barcode_metrics.csv\", sep=',')\n",
    "    #dropping columns we don't need from cellranger arc output\n",
    "    metrics = metrics.drop(columns= ['gex_barcode', 'atac_barcode', 'excluded_reason',\n",
    "       'gex_raw_reads', 'gex_mapped_reads', 'gex_conf_intergenic_reads',\n",
    "       'gex_conf_exonic_reads',  'gex_conf_intronic_reads',\n",
    "       'gex_conf_exonic_unique_reads', 'gex_conf_exonic_antisense_reads',\n",
    "       'gex_conf_exonic_dup_reads', 'gex_exonic_umis',\n",
    "       'gex_conf_intronic_unique_reads', 'gex_conf_intronic_antisense_reads',\n",
    "       'gex_conf_intronic_dup_reads', 'gex_intronic_umis',\n",
    "       'gex_conf_txomic_unique_reads', 'gex_umis_count', 'gex_genes_count'])\n",
    "    #adding in columns found in cellranger atac but not cellranger arc outputs\n",
    "    metrics['DNase_sensitive_region_fragments'] = 0\n",
    "    metrics['enhancer_region_fragments'] = 0\n",
    "    metrics['promoter_region_fragments'] = 0\n",
    "    metrics['on_target_fragments'] = metrics['atac_TSS_fragments']\n",
    "    metrics['blacklist_region_fragments'] = 0\n",
    "    #reading in barcodes from our own \"is cell\" calls\n",
    "    keep = pd.read_csv(step1_dir + sample + \"_filtered.barcodes.txt\", header = None)\n",
    "    print(sample + \" - Barcodes detected: \" + str(len(keep)))\n",
    "    #creating and setting new is_cell column\n",
    "    print(sample + \" - Creating new is_cell column\")\n",
    "    ind = 0\n",
    "    new_is_cell = []\n",
    "    for i in metrics['barcode']:\n",
    "        if i in keep[0].values:\n",
    "            new_is_cell.append(1)\n",
    "        elif i not in keep[0].values:\n",
    "            new_is_cell.append(0)\n",
    "        if ind%100000 == 0:\n",
    "            print(ind)\n",
    "        ind = ind + 1\n",
    "    metrics['is_cell'] = new_is_cell\n",
    "    \n",
    "    #replacing cellid column\n",
    "    print(sample + \" - Creating new cell_id column\")\n",
    "    numid = 1\n",
    "    ind = 1\n",
    "    cellid = []\n",
    "    for i in metrics['is_cell']:\n",
    "        if i == 0:\n",
    "            cellid = cellid + [\"None\"]\n",
    "\n",
    "        elif i == 1:\n",
    "            cellid = cellid + [\"_cell_\" + str(numid)]\n",
    "            numid = numid + 1\n",
    "\n",
    "        ind = ind + 1\n",
    "        if (ind%100000 == 0):\n",
    "            print(ind)\n",
    "\n",
    "    metrics['cellid'] = cellid           \n",
    "    #reordering columns to matching cellranger atac output (single_cell.csv)\n",
    "    order = ['barcode','atac_raw_reads','atac_dup_reads', 'atac_chimeric_reads', 'atac_unmapped_reads','atac_lowmapq',\n",
    "             'atac_mitochondrial_reads','atac_fragments', 'cellid',  'is_cell','atac_TSS_fragments',\n",
    "              'DNase_sensitive_region_fragments', 'enhancer_region_fragments','promoter_region_fragments', \n",
    "              'on_target_fragments','blacklist_region_fragments','atac_peak_region_fragments','atac_peak_region_cutsites']\n",
    "\n",
    "    metrics = metrics[order]\n",
    "    #save output\n",
    "    metrics.to_csv(step4_dir + sample + \"_singlecell.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workin on: QY_2047_1_2_QY_2046_1_2\n",
      "QY_2047_1_2_QY_2046_1_2 - Barcodes detected: 8241\n",
      "QY_2047_1_2_QY_2046_1_2 - Creating new is_cell column\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "QY_2047_1_2_QY_2046_1_2 - Creating new cell_id column\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "Workin on: QY_2041_1_2_QY_2040_1_2\n",
      "QY_2041_1_2_QY_2040_1_2 - Barcodes detected: 11648\n",
      "QY_2041_1_2_QY_2040_1_2 - Creating new is_cell column\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "QY_2041_1_2_QY_2040_1_2 - Creating new cell_id column\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "Workin on: QY_1967_1_2_QY_1966_1_2\n",
      "QY_1967_1_2_QY_1966_1_2 - Barcodes detected: 8157\n",
      "QY_1967_1_2_QY_1966_1_2 - Creating new is_cell column\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "QY_1967_1_2_QY_1966_1_2 - Creating new cell_id column\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "Workin on: QY_1882_1_2_QY_1881_1_2\n",
      "QY_1882_1_2_QY_1881_1_2 - Barcodes detected: 9452\n",
      "QY_1882_1_2_QY_1881_1_2 - Creating new is_cell column\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "QY_1882_1_2_QY_1881_1_2 - Creating new cell_id column\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n"
     ]
    }
   ],
   "source": [
    "num_cores = 1 # set the number of cores to use here\n",
    "\n",
    "with Pool(processes=num_cores) as pool:\n",
    "    pool.map(process_sample, range(len(sample_ls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Amulet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perma dirs\n",
    "amulet = \"/nfs/lab/katha/multiomics/amulet_zip/AMULET.sh\"\n",
    "amulet_dir = \"/nfs/lab/katha/multiomics/amulet_zip/\"\n",
    "autosomes_file = \"/nfs/lab/katha/multiomics/AMULET/human_autosomes.txt\"\n",
    "blacklist_file = \"/nfs/lab/katha/multiomics/AMULET/RepeatFilterFiles/blacklist_repeats_segdups_rmsk_hg38.bed\"\n",
    "output_dir = step4_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/nfs/lab/projects/mega_heart/CAREHF/multiome/Analysys/4_Doublet_cleanup/amulet/QY_2047_1_2_QY_2046_1_2/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/nfs/lab/Luca/TMP/ipykernel_1673418/2068412958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Set sample variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msample_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_ls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep4_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_ID\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/nfs/lab/projects/mega_heart/CAREHF/multiome/Analysys/4_Doublet_cleanup/amulet/QY_2047_1_2_QY_2046_1_2/'"
     ]
    }
   ],
   "source": [
    "## Make sample dirs\n",
    "for i in range(len(sample_ls)):\n",
    "    # Set sample variable\n",
    "    sample_ID = sample_ls[i]\n",
    "    os.mkdir(step4_dir + sample_ID + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_ls = []\n",
    "for i in range(len(sample_ls)):\n",
    "    # Set sample variable\n",
    "    sample = sample_ls[i]\n",
    "    sample_ID = sample_ls[i]\n",
    "    bam_file = cellranger_outs_ls[i] + \"atac_possorted_bam.bam\"\n",
    "    single_cell_csv = step4_dir + sample_ID + \"_singlecell.csv\"\n",
    "    output_dir = step4_dir + sample_ID + \"/\"\n",
    "    log = \"2> /nfs/lab/projects/mega_heart/CAREHF/multiome/log/\" + str(date.today()) + \"_\" + sample_ID + \"_Amulet.log\"\n",
    "    # Build the command string\n",
    "    command_ls.append([amulet + \n",
    "            \" --forcesorted\"+ \" --bambc\"+ \" CB\"+ \" --bcidx\"+  \" 0\" + \" --cellidx\"+ \" 8\"+ \" --iscellidx\"+ \" 9\" +\n",
    "               \" \" + bam_file + \" \" + single_cell_csv +\n",
    "               \" \" + autosomes_file + \" \" + blacklist_file + \" \" + output_dir + \" \" + amulet_dir +\n",
    "               \" \" + log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/nfs/lab/katha/multiomics/amulet_zip/AMULET.sh --forcesorted --bambc CB --bcidx 0 --cellidx 8 --iscellidx 9 /nfs/lab/projects/CARE_HF/DATA/multiome/LA/QY_2047_1_2_QY_2046_1_2/outs/atac_possorted_bam.bam /nfs/lab/projects/mega_heart/CAREHF/multiome/Analysys/4_Doublet_cleanup/amulet/QY_2047_1_2_QY_2046_1_2_singlecell.csv /nfs/lab/katha/multiomics/AMULET/human_autosomes.txt /nfs/lab/katha/multiomics/AMULET/RepeatFilterFiles/blacklist_repeats_segdups_rmsk_hg38.bed /nfs/lab/projects/mega_heart/CAREHF/multiome/Analysys/4_Doublet_cleanup/amulet/QY_2047_1_2_QY_2046_1_2/ /nfs/lab/katha/multiomics/amulet_zip/ 2> /nfs/lab/projects/mega_heart/CAREHF/multiome/log/2024-09-27_QY_2047_1_2_QY_2046_1_2_Amulet.log']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to run each command\n",
    "def run_command(i):\n",
    "    subprocess.run(command_ls[i], shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 1\n",
      "Reading BAM file.\n",
      "0\n",
      "10000000\n",
      "20000000\n",
      "30000000\n",
      "40000000\n",
      "50000000\n",
      "60000000\n",
      "70000000\n",
      "80000000\n",
      "90000000\n",
      "100000000\n",
      "110000000\n",
      "120000000\n",
      "130000000\n",
      "140000000\n",
      "150000000\n",
      "160000000\n",
      "170000000\n",
      "180000000\n",
      "190000000\n",
      "200000000\n",
      "210000000\n",
      "220000000\n",
      "230000000\n",
      "240000000\n",
      "250000000\n",
      "260000000\n",
      "270000000\n",
      "280000000\n",
      "290000000\n",
      "300000000\n",
      "310000000\n",
      "320000000\n",
      "330000000\n",
      "340000000\n",
      "350000000\n",
      "360000000\n",
      "370000000\n",
      "380000000\n",
      "390000000\n",
      "400000000\n"
     ]
    }
   ],
   "source": [
    "# Set the number of cores to use\n",
    "cores = 1\n",
    "\n",
    "# Create a ThreadPoolExecutor with the specified number of cores\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=cores) as executor:\n",
    "    # Submit each command to the executor\n",
    "    futures = [executor.submit(run_command, i) for i in range(len(command_ls))]\n",
    "\n",
    "    # Wait for all the commands to finish\n",
    "    concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running those who didn't make it - for reasons unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ls = ['QY_2047_1_2_QY_2046_1_2', 'QY_2041_1_2_QY_2040_1_2',\n",
    "             'QY_1967_1_2_QY_1966_1_2', 'QY_1882_1_2_QY_1881_1_2'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QY_2047_1_2_QY_2046_1_2\n",
      "/nfs/lab/projects/CARE_HF/DATA/multiome/LA/QY_2047_1_2_QY_2046_1_2/outs/\n"
     ]
    }
   ],
   "source": [
    "# Subset the dataframe based on the sample_ls while maintaining the order\n",
    "subset_sample_info = sample_info.set_index(\"ID\").loc[sample_ls].reset_index()\n",
    "\n",
    "# Build cellranger_outs_ls ensuring the order matches sample_ls\n",
    "cellranger_outs_ls = [\n",
    "    f\"{row['CellRanger']}{row['Chamber']}/{row['ID']}/outs/\"\n",
    "    for _, row in subset_sample_info.iterrows()\n",
    "]\n",
    "\n",
    "# Check the paths are correct\n",
    "print(sample_ls[0])\n",
    "print(cellranger_outs_ls[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

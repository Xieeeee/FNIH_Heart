{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78dcc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import gc\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "964e124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where sample folders are stored\n",
    "base_dir = \"/nfs/lab/projects/mega_heart/Upload/reference/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcff1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Define file paths for the counts matrix, features, and barcodes\n",
    "    matrix_path = os.path.join(base_dir, \"ATAC_counts.mtx\")\n",
    "    features_path = os.path.join(base_dir, \"ATAC_features.tsv\")\n",
    "    barcodes_path = os.path.join(base_dir, \"Multiome_Barcodes.tsv\")\n",
    "    \n",
    "    # Load the sparse matrix and convert to CSR format for efficient slicing\n",
    "    matrix = mmread(matrix_path).tocsr()\n",
    "    \n",
    "    # Load features and barcodes. Each file is assumed to have one entry per line without headers.\n",
    "    features = pd.read_csv(features_path, sep=\"\\t\", header=None, squeeze=True).tolist()\n",
    "    barcodes = pd.read_csv(barcodes_path, sep=\"\\t\", header=None, squeeze=True).tolist()\n",
    "    \n",
    "    # Create an AnnData object using the matrix (X), features as variables, and barcodes as observations.\n",
    "    adata = anndata.AnnData(\n",
    "        X=matrix.T,  # Now rows are cells, columns are features\n",
    "        obs=pd.DataFrame(index=barcodes),  # (cells\n",
    "        var=pd.DataFrame(index=features)     # features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7080effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your output directory and file name\n",
    "output_dir = \"/nfs/lab/projects/mega_heart/Upload/reference\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "h5ad_path = os.path.join(output_dir, \"ATAC_FNIH_Multiome.h5ad\")\n",
    "\n",
    "# Save the AnnData object in h5ad format\n",
    "adata.write_h5ad(h5ad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57512d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed file saved to: /nfs/lab/projects/mega_heart/Upload/reference/ATAC_FNIH_Multiome.h5ad.gz\n"
     ]
    }
   ],
   "source": [
    "# Define input and output paths\n",
    "input_path = \"/nfs/lab/projects/mega_heart/Upload/reference/ATAC_FNIH_Multiome.h5ad\"\n",
    "output_path = \"/nfs/lab/projects/mega_heart/Upload/reference/ATAC_FNIH_Multiome.h5ad.gz\"\n",
    "\n",
    "# Compress the file\n",
    "with open(input_path, 'rb') as f_in:\n",
    "    with gzip.open(output_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f\"Compressed file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10461a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CareHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import anndata\n",
    "\n",
    "# Base directory containing sample folders\n",
    "base_dir = \"/nfs/lab/projects/mega_heart/CAREHF/multiome/Analysys/4_Doublet_cleanup/MM_counts/\"\n",
    "\n",
    "# List all sample folders (each folder is a sample)\n",
    "sample_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "adata_list = []\n",
    "sample_names = []\n",
    "\n",
    "for sample in sample_dirs:\n",
    "    sample_path = os.path.join(base_dir, sample)\n",
    "    \n",
    "    # Define file paths for the counts matrix, features, and barcodes\n",
    "    counts_file = os.path.join(sample_path, \"ATAC_counts.mtx\")\n",
    "    features_file = os.path.join(sample_path, \"ATAC_features.tsv\")\n",
    "    barcodes_file = os.path.join(sample_path, \"Barcodes.tsv\")\n",
    "    \n",
    "    # Load the sparse counts matrix (in CSR format)\n",
    "    matrix = mmread(counts_file).tocsr()\n",
    "    \n",
    "    # Load features and barcodes; each file is assumed to have one entry per line\n",
    "    features = pd.read_csv(features_file, sep=\"\\t\", header=None, squeeze=True).tolist()\n",
    "    barcodes = pd.read_csv(barcodes_file, sep=\"\\t\", header=None, squeeze=True).tolist()\n",
    "    \n",
    "    # Create an AnnData object.\n",
    "    # Transpose so that cells (barcodes) become rows (observations)\n",
    "    adata = anndata.AnnData(\n",
    "        X=matrix.T,  # Now shape: (n_cells, n_features)\n",
    "        obs=pd.DataFrame(index=barcodes),   # Observations: cells\n",
    "        var=pd.DataFrame(index=features)      # Variables: features\n",
    "    )\n",
    "    \n",
    "    # Optionally, add the sample name as an observation-level metadata\n",
    "    adata.obs[\"sample\"] = sample\n",
    "    \n",
    "    # Only add non-empty AnnData objects to the list\n",
    "    if adata.n_obs > 0:\n",
    "        adata_list.append(adata)\n",
    "        sample_names.append(sample)\n",
    "    else:\n",
    "        print(f\"Warning: Sample {sample} produced an empty AnnData object and will be skipped.\")\n",
    "\n",
    "# Now merge using the keys based on the folder (sample) names\n",
    "merged_adata = anndata.concat(\n",
    "    adata_list,         # List of AnnData objects to merge.\n",
    "    join=\"outer\",       # Use \"outer\" join to include all features from all samples.\n",
    "    keys=sample_names,  # Use the validated sample_names list as keys.\n",
    "    label=\"sample\",     # The new column in obs that will store the sample name.\n",
    "    axis=0              # Concatenating along the observation (cell) axis.\n",
    ")\n",
    "\n",
    "print(merged_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your output directory and file name\n",
    "output_dir = \"/nfs/lab/projects/mega_heart/Upload/ATACpart_CAREHF\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "h5ad_path = os.path.join(output_dir, \"ATACpart_CAREHF.h5ad\")\n",
    "\n",
    "# Save the AnnData object in h5ad format\n",
    "merged_adata.write_h5ad(h5ad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba20356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed file saved to: /nfs/lab/projects/mega_heart/Upload/ATACpart_CAREHF/ATAC_CAREHF_Multiome.h5ad.gz\n"
     ]
    }
   ],
   "source": [
    "# Define input and output paths\n",
    "input_path = \"/nfs/lab/projects/mega_heart/Upload/ATACpart_CAREHF/ATACpart_CAREHF.h5ad\"\n",
    "output_path = \"/nfs/lab/projects/mega_heart/Upload/ATACpart_CAREHF/ATAC_CAREHF_Multiome.h5ad.gz\"\n",
    "\n",
    "# Compress the file\n",
    "with open(input_path, 'rb') as f_in:\n",
    "    with gzip.open(output_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f\"Compressed file saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cdd597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
